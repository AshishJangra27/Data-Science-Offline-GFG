{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEeqA67VzpHC"
      },
      "source": [
        "# California Housing Price Prediction using ANN\n",
        "\n",
        "## Introduction\n",
        "This notebook uses the California Housing dataset to predict house prices using a complex Artificial Neural Network (ANN) architecture. The aim is to demonstrate regression with neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlod9BTFzpHE"
      },
      "source": [
        "## 1. Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AC62f6zzpHE"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load data\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL7o5g6AzpHF"
      },
      "source": [
        "## 2. Building an ANN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YimhL023zpHF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.1),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.1),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlA4MN92zpHF"
      },
      "source": [
        "## 3. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw_hDahHzpHG",
        "outputId": "f01cf72f-3b12-42ba-ef74-bfde692b138c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 1.1424 - mae: 0.7731 - val_loss: 0.4848 - val_mae: 0.4927\n",
            "Epoch 2/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.4712 - mae: 0.5045 - val_loss: 0.3801 - val_mae: 0.4312\n",
            "Epoch 3/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4245 - mae: 0.4760 - val_loss: 0.3765 - val_mae: 0.4360\n",
            "Epoch 4/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.4002 - mae: 0.4563 - val_loss: 0.3552 - val_mae: 0.4333\n",
            "Epoch 5/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.3905 - mae: 0.4508 - val_loss: 0.3610 - val_mae: 0.4287\n",
            "Epoch 6/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.3806 - mae: 0.4440 - val_loss: 0.3534 - val_mae: 0.4024\n",
            "Epoch 7/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3570 - mae: 0.4288 - val_loss: 0.3600 - val_mae: 0.4174\n",
            "Epoch 8/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.3566 - mae: 0.4252 - val_loss: 0.3463 - val_mae: 0.4209\n",
            "Epoch 9/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3649 - mae: 0.4296 - val_loss: 0.3284 - val_mae: 0.3884\n",
            "Epoch 10/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3365 - mae: 0.4094 - val_loss: 0.3381 - val_mae: 0.4050\n",
            "Epoch 11/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.3362 - mae: 0.4125 - val_loss: 0.3473 - val_mae: 0.4155\n",
            "Epoch 12/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3326 - mae: 0.4102 - val_loss: 0.3504 - val_mae: 0.4231\n",
            "Epoch 13/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3266 - mae: 0.4098 - val_loss: 0.3193 - val_mae: 0.3811\n",
            "Epoch 14/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3265 - mae: 0.4049 - val_loss: 0.3363 - val_mae: 0.4191\n",
            "Epoch 15/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3172 - mae: 0.3966 - val_loss: 0.3626 - val_mae: 0.4145\n",
            "Epoch 16/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3161 - mae: 0.3962 - val_loss: 0.3304 - val_mae: 0.3815\n",
            "Epoch 17/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3224 - mae: 0.4001 - val_loss: 0.3435 - val_mae: 0.4233\n",
            "Epoch 18/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3152 - mae: 0.3965 - val_loss: 0.3518 - val_mae: 0.3961\n",
            "Epoch 19/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3039 - mae: 0.3879 - val_loss: 0.3166 - val_mae: 0.3825\n",
            "Epoch 20/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2996 - mae: 0.3859 - val_loss: 0.3177 - val_mae: 0.3882\n",
            "Epoch 21/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2938 - mae: 0.3858 - val_loss: 0.3320 - val_mae: 0.4036\n",
            "Epoch 22/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3050 - mae: 0.3893 - val_loss: 0.3536 - val_mae: 0.4300\n",
            "Epoch 23/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2985 - mae: 0.3825 - val_loss: 0.3213 - val_mae: 0.3818\n",
            "Epoch 24/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3019 - mae: 0.3835 - val_loss: 0.3181 - val_mae: 0.3810\n",
            "Epoch 25/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2993 - mae: 0.3799 - val_loss: 0.3315 - val_mae: 0.4234\n",
            "Epoch 26/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2878 - mae: 0.3791 - val_loss: 0.3334 - val_mae: 0.4002\n",
            "Epoch 27/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3011 - mae: 0.3839 - val_loss: 0.3260 - val_mae: 0.3978\n",
            "Epoch 28/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2863 - mae: 0.3779 - val_loss: 0.3189 - val_mae: 0.3997\n",
            "Epoch 29/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2835 - mae: 0.3730 - val_loss: 0.3250 - val_mae: 0.4074\n",
            "Epoch 30/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2876 - mae: 0.3740 - val_loss: 0.3043 - val_mae: 0.3822\n",
            "Epoch 31/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3059 - mae: 0.3815 - val_loss: 0.3261 - val_mae: 0.4015\n",
            "Epoch 32/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2862 - mae: 0.3737 - val_loss: 0.3011 - val_mae: 0.3754\n",
            "Epoch 33/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2853 - mae: 0.3698 - val_loss: 0.3071 - val_mae: 0.3862\n",
            "Epoch 34/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2771 - mae: 0.3692 - val_loss: 0.3164 - val_mae: 0.3955\n",
            "Epoch 35/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2777 - mae: 0.3678 - val_loss: 0.3205 - val_mae: 0.3902\n",
            "Epoch 36/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2670 - mae: 0.3614 - val_loss: 0.3151 - val_mae: 0.3877\n",
            "Epoch 37/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2781 - mae: 0.3635 - val_loss: 0.2963 - val_mae: 0.3716\n",
            "Epoch 38/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2824 - mae: 0.3712 - val_loss: 0.3054 - val_mae: 0.3920\n",
            "Epoch 39/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2791 - mae: 0.3654 - val_loss: 0.3170 - val_mae: 0.4084\n",
            "Epoch 40/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2778 - mae: 0.3683 - val_loss: 0.3094 - val_mae: 0.3741\n",
            "Epoch 41/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2672 - mae: 0.3629 - val_loss: 0.2951 - val_mae: 0.3735\n",
            "Epoch 42/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2754 - mae: 0.3639 - val_loss: 0.2960 - val_mae: 0.3805\n",
            "Epoch 43/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2699 - mae: 0.3651 - val_loss: 0.2955 - val_mae: 0.3699\n",
            "Epoch 44/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2654 - mae: 0.3610 - val_loss: 0.2983 - val_mae: 0.3806\n",
            "Epoch 45/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2688 - mae: 0.3584 - val_loss: 0.3364 - val_mae: 0.4153\n",
            "Epoch 46/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2670 - mae: 0.3606 - val_loss: 0.2955 - val_mae: 0.3725\n",
            "Epoch 47/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2632 - mae: 0.3602 - val_loss: 0.2843 - val_mae: 0.3589\n",
            "Epoch 48/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2664 - mae: 0.3583 - val_loss: 0.3083 - val_mae: 0.3798\n",
            "Epoch 49/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2646 - mae: 0.3569 - val_loss: 0.3034 - val_mae: 0.3804\n",
            "Epoch 50/50\n",
            "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2674 - mae: 0.3579 - val_loss: 0.3183 - val_mae: 0.4101\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFjRcoXmzpHG"
      },
      "source": [
        "## 4. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aroh384VzpHG",
        "outputId": "9b6c40dd-d6b5-46aa-e419-be80aa2334d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2983 - mae: 0.3994\n",
            "Test Mean Absolute Error: 0.4014\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f'Test Mean Absolute Error: {test_mae:.4f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}