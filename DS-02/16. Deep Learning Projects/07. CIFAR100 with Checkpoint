{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtQl5VhO9upB"
      },
      "source": [
        "# Advanced CIFAR-100 Classification using TensorFlow\n",
        "\n",
        "## Introduction\n",
        "This notebook demonstrates an advanced approach to building a convolutional neural network (CNN) using TensorFlow to classify images from the CIFAR-100 dataset. This dataset includes 100 classes making it a challenging problem for image classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zv2qzlW9upD"
      },
      "source": [
        "## 1. Data Loading\n",
        "Load the CIFAR-100 dataset from TensorFlow's Keras API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbk_gLKn9upD",
        "outputId": "879c5bba-0d24-4655-81b0-aa71472b3a46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUR8Kiqk9upE"
      },
      "source": [
        "## 2. Data Preprocessing and Augmentation\n",
        "Normalize the data and set up an image data augmentation pipeline to improve training efficiency and model generalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hkH2ARBo9upE"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data normalization\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2\n",
        ")\n",
        "train_datagen.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCs_bD3X9upF"
      },
      "source": [
        "## 3. Building a Complex CNN Model\n",
        "Construct a CNN architecture with multiple convolutional and pooling layers, dropout for regularization, and batch normalization for faster convergence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SamlFgU29upF",
        "outputId": "149e3bc5-d46b-4e39-afff-f3c2f820c961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(100, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t74ulgXz9upF"
      },
      "source": [
        "## 4. Model Training with Callbacks\n",
        "Train the CNN using callbacks like ModelCheckpoint and EarlyStopping to save the best model and avoid overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw4bmvhG9upF",
        "outputId": "f38d1f30-89ba-4d91-fbda-d8e56fb28b08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 407ms/step - accuracy: 0.0382 - loss: 4.6839 - val_accuracy: 0.1203 - val_loss: 3.7700\n",
            "Epoch 2/100\n",
            "\u001b[1m196/782\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:52\u001b[0m 398ms/step - accuracy: 0.0924 - loss: 3.9301"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss', mode='min')  # Change here\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(train_datagen.flow(X_train, y_train, batch_size=64),\n",
        "                    epochs=100,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[checkpoint, early_stop])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3ANj_ry9upG"
      },
      "source": [
        "## 5. Evaluating the Model\n",
        "Load the best model saved during training and evaluate its performance on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXV_ng8A9upG"
      },
      "outputs": [],
      "source": [
        "best_model = tf.keras.models.load_model('best_model.h5')\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YdN7yAm9upG"
      },
      "source": [
        "## 6. Conclusion and Further Steps\n",
        "Discuss how the model performed and explore potential improvements or further experiments that could enhance model accuracy or efficiency."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}